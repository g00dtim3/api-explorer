"""
Module 3 - Export Bulk (Masse)
Permet d'exporter massivement par marque sans s√©lection individuelle
"""
import streamlit as st
import pandas as pd
import io
import json
import time
from api_client import api_client
from utils import (
    initialize_session_state,
    build_filter_params,
    load_configuration_from_json,
    export_configuration_to_json,
    generate_export_filename,
    postprocess_reviews,
    display_quotas,
    log_export_activity,
    create_excel_download,
    display_download_buttons,
    display_excel_warning
)


def display_configuration_interface():
    """Interface de chargement de configuration pour export bulk"""
    st.header("üì• Configuration d'export bulk")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üìé Charger une configuration existante")
        json_input = st.text_area(
            "Collez votre configuration JSON ici",
            height=200,
            help="Configuration g√©n√©r√©e par le Module 1 - Explorateur ou Module 2"
        )
        
        if st.button("üîÑ Charger la configuration", type="primary"):
            if load_configuration_from_json(json_input):
                st.success("Configuration charg√©e avec succ√®s !")
                # En mode bulk, on ignore la s√©lection sp√©cifique de produits
                st.info("‚ÑπÔ∏è Mode bulk : La s√©lection sp√©cifique de produits sera ignor√©e")
                st.rerun()
    
    with col2:
        st.markdown("### üìã Configuration actuelle")
        if st.session_state.get("filters"):
            filters = st.session_state.filters
            
            st.metric("Marques", len(filters.get("brand", [])))
            st.metric("Cat√©gorie", filters.get("category", "ALL"))
            st.metric("P√©riode", f"{filters.get('start_date')} ‚Üí {filters.get('end_date')}")
            
            if st.button("üóëÔ∏è Effacer la configuration"):
                st.session_state.filters = {}
                st.session_state.selected_product_ids = []
                st.session_state.apply_filters = False
                st.rerun()
        else:
            st.info("Aucune configuration charg√©e")


def display_bulk_configuration_summary():
    """Affiche le r√©sum√© de la configuration pour export bulk"""
    if not st.session_state.get("filters"):
        return
    
    filters = st.session_state.filters
    
    st.markdown("---")
    st.header("üìã Configuration d'export bulk")
    
    # R√©sum√© des filtres
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üîç Filtres appliqu√©s")
        st.markdown(f"**üìÖ P√©riode :** `{filters['start_date']}` ‚Üí `{filters['end_date']}`")
        st.markdown(f"**üè∑Ô∏è Cat√©gorie :** `{filters.get('category', 'ALL')}`")
        st.markdown(f"**üè∑Ô∏è Sous-cat√©gorie :** `{filters.get('subcategory', 'ALL')}`")
        st.markdown(f"**üåç Pays :** `{', '.join(filters.get('country', [])) if filters.get('country') and 'ALL' not in filters.get('country', []) else 'Tous'}`")
    
    with col2:
        st.markdown("### üè¢ Marques s√©lectionn√©es")
        brands = filters.get("brand", [])
        if brands:
            st.markdown(f"**üì¶ Nombre de marques :** `{len(brands)}`")
            
            # Afficher les marques
            brands_text = ", ".join(f"`{brand}`" for brand in brands[:5])
            if len(brands) > 5:
                brands_text += f" ... (+{len(brands) - 5} autres)"
            st.markdown(f"**Marques :** {brands_text}")
        else:
            st.warning("‚ö†Ô∏è Aucune marque s√©lectionn√©e")
    
    # Estimation du volume total
    if brands:
        display_bulk_volume_estimation()


def display_bulk_volume_estimation():
    """Estime le volume total pour l'export bulk"""
    filters = st.session_state.filters
    brands = filters.get("brand", [])
    
    if not brands:
        st.warning("‚ö†Ô∏è Aucune marque s√©lectionn√©e")
        return
    
    st.markdown("### üìä Estimation du volume bulk")
    
    # Bouton pour calculer le volume global
    if st.button("üìà Calculer le volume total par marque", key="estimate_bulk_volume"):
        calculate_bulk_volume(filters, brands)
    
    # Affichage des r√©sultats s'ils existent
    display_bulk_volume_results(brands)


def calculate_bulk_volume(filters, brands):
    """Calcule et stocke le volume bulk"""
    with st.spinner("Calcul du volume bulk..."):
        try:
            # Param√®tres pour toutes les marques en une fois
            bulk_params = build_filter_params(filters)
            
            # Appel API pour obtenir les m√©triques globales
            metrics = api_client.get_metrics(**bulk_params)
            if metrics:
                total_reviews = metrics.get("nbDocs", 0)
                
                # Stocker les r√©sultats dans session_state
                st.session_state.bulk_volume_results = {
                    "total_reviews": total_reviews,
                    "brands_count": len(brands),
                    "avg_per_brand": total_reviews / len(brands) if brands else 0,
                    "calculated": True
                }
                
                st.success(f"‚úÖ Volume calcul√© : {total_reviews:,} reviews pour {len(brands)} marques")
            else:
                st.error("‚ùå Impossible d'obtenir les m√©triques globales")
                
        except Exception as e:
            st.error(f"‚ùå Erreur lors du calcul : {e}")


def display_bulk_volume_results(brands):
    """Affiche les r√©sultats du calcul bulk s'ils existent"""
    bulk_results = st.session_state.get("bulk_volume_results", {})
    
    if not bulk_results.get("calculated"):
        return
    
    # Affichage des m√©triques principales
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìä Volume total estim√©", f"{bulk_results['total_reviews']:,} reviews")
    with col2:
        st.metric("üè¢ Marques", bulk_results['brands_count'])
    with col3:
        st.metric("üìà Moyenne par marque", f"{bulk_results['avg_per_brand']:.0f} reviews")
    
    # Section d√©tail par marque (s√©par√©e du bouton principal)
    st.markdown("---")
    st.markdown("#### üìã D√©tail par marque")
    
    # Checkbox s√©par√©e avec sa propre logique
    show_details = st.checkbox("Afficher le d√©tail par marque", key="show_brand_details_bulk")
    
    if show_details:
        calculate_and_display_brand_details(brands, bulk_results['total_reviews'])
    
    # Stocker pour l'interface d'export
    st.session_state.estimated_bulk_volume = bulk_results['total_reviews']


def calculate_and_display_brand_details(brands, total_reviews):
    """Calcule et affiche le d√©tail par marque"""
    filters = st.session_state.filters
    
    # V√©rifier si on a d√©j√† calcul√© les d√©tails
    if "brand_details_cache" not in st.session_state:
        st.session_state.brand_details_cache = {}
    
    # Bouton pour recalculer les d√©tails
    col1, col2 = st.columns([1, 3])
    
    with col1:
        if st.button("üîÑ Calculer d√©tails", key="calc_brand_details"):
            calculate_brand_details(brands, filters)
    
    with col2:
        if st.session_state.brand_details_cache:
            st.info(f"Derniers d√©tails calcul√©s pour {len(st.session_state.brand_details_cache)} marques")
    
    # Affichage des d√©tails s'ils existent
    if st.session_state.brand_details_cache:
        display_brand_details_table(total_reviews)


def calculate_brand_details(brands, filters):
    """Calcule les d√©tails par marque"""
    with st.spinner("Calcul du d√©tail par marque..."):
        brand_details = {}
        progress_bar = st.progress(0)
        
        for i, brand in enumerate(brands):
            progress = (i + 1) / len(brands)
            progress_bar.progress(progress)
            
            # Param√®tres sp√©cifiques √† chaque marque
            brand_params = build_filter_params(filters)
            brand_params["brand"] = brand  # Une seule marque
            
            try:
                brand_metrics = api_client.get_metrics(**brand_params)
                brand_count = brand_metrics.get("nbDocs", 0) if brand_metrics else 0
            except Exception as e:
                st.warning(f"Erreur pour la marque {brand}: {e}")
                brand_count = 0
            
            brand_details[brand] = brand_count
        
        progress_bar.empty()
        st.session_state.brand_details_cache = brand_details
        st.success(f"‚úÖ D√©tails calcul√©s pour {len(brand_details)} marques")


def display_brand_details_table(total_reviews):
    """Affiche le tableau des d√©tails par marque"""
    brand_details = st.session_state.brand_details_cache
    
    if not brand_details:
        return
    
    # Cr√©er le DataFrame
    df_details = pd.DataFrame([
        {"Marque": brand, "Reviews": count}
        for brand, count in brand_details.items()
    ])
    
    df_details = df_details.sort_values("Reviews", ascending=False)
    st.dataframe(df_details, use_container_width=True)
    
    # V√©rification de coh√©rence
    sum_individual = df_details["Reviews"].sum()
    difference = abs(sum_individual - total_reviews)
    tolerance = total_reviews * 0.1  # 10% de tol√©rance
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Somme individuelle", f"{sum_individual:,}")
    with col2:
        st.metric("Diff√©rence", f"{difference:,}")
    
    if difference > tolerance:
        st.warning(f"‚ö†Ô∏è Diff√©rence d√©tect√©e : Total group√© ({total_reviews:,}) ‚â† Somme individuelle ({sum_individual:,})")
        st.info("üí° Cela peut √™tre normal si des reviews mentionnent plusieurs marques")
    else:
        st.success("‚úÖ Coh√©rence v√©rifi√©e entre le total group√© et la somme individuelle")


def display_bulk_export_interface():
    """Interface principale d'export bulk"""
    if not st.session_state.get("filters", {}).get("brand"):
        st.warning("‚ö†Ô∏è Aucune marque s√©lectionn√©e. Chargez d'abord une configuration valide.")
        return
    
    st.markdown("---")
    st.header("üöÄ Export bulk par marque")
    
    # Affichage des quotas
    with st.expander("üìä Quotas API actuels", expanded=False):
        display_quotas()
    
    # Options d'export bulk
    st.markdown("### ‚öôÔ∏è Options d'export bulk")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìÑ Param√®tres de pagination")
        bulk_rows_per_page = st.number_input(
            "Reviews par page (bulk)",
            min_value=10,
            max_value=1000,
            value=500,
            step=50,
            help="Plus √©lev√© = moins d'appels API mais plus de m√©moire. Recommand√©: 500+"
        )
        
        bulk_use_random = st.checkbox("Randomiser les r√©sultats (bulk)")
        if bulk_use_random:
            bulk_random_seed = st.number_input(
                "Seed al√©atoire (bulk)",
                min_value=1,
                max_value=9999,
                value=42
            )
        else:
            bulk_random_seed = None
    
    with col2:
        st.markdown("#### üéØ Mode d'export bulk")
        bulk_export_mode = st.radio(
            "Type d'export bulk",
            ["üîç Aper√ßu bulk (100 reviews max)", "üì¶ Export bulk complet"],
            help="L'aper√ßu permet de tester rapidement l'export de toutes les marques"
        )
        
        is_bulk_preview = bulk_export_mode.startswith("üîç")
        
        # Affichage de l'estimation
        estimated_volume = st.session_state.get("estimated_bulk_volume", "?")
        if is_bulk_preview:
            export_volume = min(100, estimated_volume) if isinstance(estimated_volume, int) else 100
            st.info(f"üìä Export bulk pr√©vu : {export_volume} reviews (√©chantillon)")
        else:
            st.info(f"üìä Export bulk pr√©vu : {estimated_volume} reviews (toutes les marques)")
        
        # Avantages du mode bulk
        st.success("""
        **Avantages du mode bulk :**
        ‚úÖ Pas de s√©lection produit par produit
        ‚úÖ Export rapide de milliers de reviews
        ‚úÖ Id√©al pour des analyses globales
        ‚úÖ Moins d'appels API individuels
        """)
    
    # Bouton de lancement
    st.markdown("---")
    if st.button("üöÄ Lancer l'export bulk", type="primary", key="launch_bulk_export"):
        execute_bulk_export(bulk_rows_per_page, bulk_use_random, bulk_random_seed, is_bulk_preview)


def execute_bulk_export(rows_per_page, use_random, random_seed, is_preview):
    """Ex√©cute l'export bulk"""
    
    # V√©rification anti-double-export
    if st.session_state.get('export_in_progress', False):
        st.warning("‚ö†Ô∏è Un export est d√©j√† en cours. Veuillez patienter.")
        return
    
    # Marquer l'export comme en cours
    st.session_state.export_in_progress = True
    
    try:
        filters = st.session_state.filters
        
        # Construction des param√®tres bulk (toutes les marques ensemble)
        bulk_params = build_filter_params(filters)
        # Ne pas inclure de s√©lection sp√©cifique de produits en mode bulk
        
        bulk_params["rows"] = min(rows_per_page, 100) if is_preview else rows_per_page
        
        if use_random and random_seed:
            bulk_params["random"] = str(random_seed)
        
        # Obtenir le volume total
        metrics = api_client.get_metrics(**build_filter_params(filters))
        total_available = metrics.get("nbDocs", 0) if metrics else 0
        
        if total_available == 0:
            st.warning("‚ùå Aucune review disponible pour cette combinaison de marques")
            return
        
        # Configuration selon le mode
        if is_preview:
            max_reviews = min(100, total_available)
            expected_pages = 1
            st.info(f"üìä Mode aper√ßu bulk : Chargement de {max_reviews} reviews maximum sur {total_available:,} disponibles")
        else:
            expected_pages = (total_available + rows_per_page - 1) // rows_per_page
            st.info(f"üîÑ Export bulk complet : {total_available:,} reviews sur {expected_pages} pages estim√©es")
        
        # Interface de progression
        status_text = st.empty()
        progress_bar = None if is_preview else st.progress(0)
        
        # Variables de pagination - CORRECTION PRINCIPALE
        cursor_mark = "*"  # Toujours commencer par "*"
        page_count = 0
        all_docs = []
        max_iterations = 1000 if not is_preview else 10  # Limite de s√©curit√©
        
        # Debug initial
        st.write(f"üîç Debug bulk: D√©marrage avec cursorMark='*', rows={bulk_params['rows']}")
        
        # Boucle d'export bulk
        while page_count < max_iterations:
            page_count += 1
            
            current_count = len(all_docs)
            status_text.text(f"üì• Page {page_count} | R√©cup√©r√©: {current_count:,}/{total_available:,} reviews (bulk)")
            
            # Param√®tres avec cursor - CORRECTION CRITIQUE
            current_params = bulk_params.copy()
            current_params["nextCursorMark"] = cursor_mark  # ‚úÖ CORRECTION: nextCursorMark au lieu de cursorMark
            
            # Debug des param√®tres pour les premi√®res pages
            if page_count <= 3:
                st.write(f"üîç Bulk page {page_count}: nextCursorMark='{cursor_mark}', rows={current_params['rows']}")
            
            # Appel API
            result = api_client.get_reviews(**current_params)
            
            if not result:
                st.error(f"‚ùå Erreur API √† la page {page_count}")
                break
            
            if not result.get("docs"):
                st.warning(f"‚ö†Ô∏è Pas de donn√©es √† la page {page_count}")
                break
            
            docs = result.get("docs", [])
            
            # CORRECTION PRINCIPALE: V√©rifier les doublons en mode DEV
            docs_before = len(all_docs)
            
            # En mode d√©veloppement, v√©rifier les IDs pour √©viter les doublons
            if all_docs and len(docs) > 0 and 'id' in docs[0]:
                existing_ids = {doc.get('id') for doc in all_docs if doc.get('id')}
                new_docs = [doc for doc in docs if doc.get('id') not in existing_ids]
                
                if len(new_docs) < len(docs):
                    duplicates_found = len(docs) - len(new_docs)
                    st.warning(f"‚ö†Ô∏è {duplicates_found} doublons d√©tect√©s et ignor√©s √† la page {page_count}")
                
                all_docs.extend(new_docs)
            else:
                all_docs.extend(docs)
            
            docs_after = len(all_docs)
            
            # Affichage du progr√®s d√©taill√©
            st.write(f"üìä Bulk page {page_count}: +{len(docs)} re√ßus, +{docs_after - docs_before} ajout√©s (Total: {docs_after:,})")
            
            # Mise √† jour progression
            if progress_bar is not None:
                progress_percent = min(len(all_docs) / total_available, 1.0)
                progress_bar.progress(progress_percent)
            
            # En mode aper√ßu, on s'arr√™te apr√®s avoir assez de reviews
            if is_preview and len(all_docs) >= 100:
                st.info("üîç Limite aper√ßu bulk atteinte")
                break
            
            # Gestion du cursor - CORRECTION CRITIQUE
            next_cursor = result.get("nextCursorMark")
            
            # Debug du cursor pour les premi√®res pages
            if page_count <= 3:
                st.write(f"üîç Bulk cursor re√ßu: '{next_cursor}'")
                st.write(f"üîç Bulk cursor actuel: '{cursor_mark}'")
                st.write(f"üîç Bulk cursor identique: {next_cursor == cursor_mark}")
            
            # CONDITIONS D'ARR√äT
            if not next_cursor:
                st.info(f"üèÅ Fin bulk: Pas de nextCursorMark")
                break
            
            if next_cursor == cursor_mark:
                st.info(f"üèÅ Fin bulk: Cursor identique ('{cursor_mark}')")
                break
            
            # MISE √Ä JOUR DU CURSOR - POINT CRITIQUE
            cursor_mark = next_cursor
            
            # Conditions d'arr√™t suppl√©mentaires
            if len(all_docs) >= total_available:
                st.info(f"üèÅ Toutes les reviews bulk r√©cup√©r√©es ({len(all_docs):,})")
                break
            
            # Pause entre requ√™tes pour √©viter les limites
            if page_count % 5 == 0:
                time.sleep(0.1)
        
        # Stocker les r√©sultats
        st.session_state.all_docs = all_docs
        st.session_state.export_params = bulk_params
        st.session_state.is_preview_mode = is_preview
        
        # Messages finaux
        mode_text = "aper√ßu bulk" if is_preview else "export bulk complet"
        if all_docs:
            success_msg = f"‚úÖ {mode_text.capitalize()} termin√©! {len(all_docs):,} reviews r√©cup√©r√©es sur {total_available:,} attendues"
            status_text.text(success_msg)
            
            # Avertissement si pas toutes les reviews en mode complet
            if len(all_docs) < total_available and not is_preview:
                missing_reviews = total_available - len(all_docs)
                st.warning(f"‚ö†Ô∏è Attention: {missing_reviews:,} reviews manquantes")
                st.info("üí° Cela peut √™tre d√ª aux limites de pagination en environnement DEV")
            
            st.balloons()  # C√©l√©bration pour les gros exports !
            
            # Log de l'activit√©
            if not is_preview:
                log_export_activity(bulk_params, len(all_docs), "BULK_BY_BRAND")
            
        else:
            status_text.text("‚ö†Ô∏è Aucune review r√©cup√©r√©e en mode bulk")
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors de l'export bulk : {str(e)}")
        st.write(f"üîç Debug: Page {page_count if 'page_count' in locals() else 0}, Reviews r√©cup√©r√©es: {len(all_docs) if 'all_docs' in locals() else 0}")
    
    finally:
        # Toujours lib√©rer le verrou
        st.session_state.export_in_progress = False


def display_bulk_export_results():
    """Affiche les r√©sultats de l'export bulk"""
    if not st.session_state.get("all_docs"):
        return
    
    docs = st.session_state.all_docs
    total_results = len(docs)
    is_preview = st.session_state.get("is_preview_mode", False)
    
    st.markdown("---")
    st.header("üìã R√©sultats de l'export bulk")
    
    # Bandeau d'information
    if is_preview:
        st.info("‚ÑπÔ∏è Mode aper√ßu bulk - √âchantillon repr√©sentatif de toutes les marques")
    else:
        st.success(f"‚úÖ Export bulk complet - {total_results:,} reviews de toutes les marques s√©lectionn√©es")
    
    # Statistiques rapides
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Total reviews", f"{total_results:,}")
    
    with col2:
        # Compter les marques uniques dans les r√©sultats
        df_temp = pd.json_normalize(docs)
        unique_brands = df_temp.get('brand', pd.Series()).nunique() if 'brand' in df_temp.columns else "N/A"
        st.metric("üè¢ Marques repr√©sent√©es", unique_brands)
    
    with col3:
        # Compter les produits uniques
        unique_products = df_temp.get('product', pd.Series()).nunique() if 'product' in df_temp.columns else "N/A"
        st.metric("üì¶ Produits uniques", unique_products)
    
    with col4:
        # P√©riode couverte
        if 'date' in df_temp.columns:
            date_range = "Voir donn√©es"
        else:
            date_range = "N/A"
        st.metric("üìÖ P√©riode", date_range)
    
    # Pagination pour l'affichage
    rows_per_page = 100
    total_pages = max(1, (total_results + rows_per_page - 1) // rows_per_page)
    
    # Contr√¥les de pagination
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        if st.button("‚¨ÖÔ∏è Page pr√©c√©dente", disabled=st.session_state.get("current_page", 1) <= 1):
            st.session_state.current_page = max(1, st.session_state.get("current_page", 1) - 1)
            st.rerun()
    
    with col2:
        current_page = st.selectbox(
            "Page",
            range(1, total_pages + 1),
            index=st.session_state.get("current_page", 1) - 1,
            key="bulk_page_selector"
        )
        st.session_state.current_page = current_page
    
    with col3:
        if st.button("‚û°Ô∏è Page suivante", disabled=st.session_state.get("current_page", 1) >= total_pages):
            st.session_state.current_page = min(total_pages, st.session_state.get("current_page", 1) + 1)
            st.rerun()
    
    # Affichage des donn√©es de la page courante
    start_idx = (current_page - 1) * rows_per_page
    end_idx = min(start_idx + rows_per_page, total_results)
    page_docs = docs[start_idx:end_idx]
    
    st.write(f"Affichage des reviews {start_idx + 1} √† {end_idx} sur {total_results:,} (Export bulk)")
    
    # Cr√©er le DataFrame
    df_page = pd.json_normalize(page_docs)
    df_page = df_page.applymap(lambda x: str(x) if isinstance(x, (dict, list)) else x)
    
    # Afficher le tableau
    st.dataframe(df_page, use_container_width=True)
    
    # Boutons de t√©l√©chargement
    display_bulk_download_interface(docs, df_page, current_page)


def display_bulk_download_interface(all_docs, df_page, current_page):
    """Interface de t√©l√©chargement des r√©sultats bulk"""
    is_preview = st.session_state.get("is_preview_mode", False)
    
    st.markdown("### üíæ T√©l√©chargements bulk")
    
    # Avertissement Excel si n√©cessaire
    display_excel_warning()
    
    # T√©l√©chargement de la page courante
    st.markdown("#### üìÑ Page courante")
    
    page_filename_base = f"reviews_bulk_page{current_page}"
    display_download_buttons(df_page, page_filename_base, mode="page", page=current_page)
    
    # T√©l√©chargement complet bulk
    st.markdown("#### üì¶ Export bulk complet")
    
    # Pr√©parer les donn√©es compl√®tes
    df_full = pd.json_normalize(all_docs)
    df_full = df_full.applymap(lambda x: str(x) if isinstance(x, (dict, list)) else x)
    
    # Informations sur le dataset complet
    st.info(f"üìä Dataset complet : {len(all_docs):,} reviews, {df_full.shape[1]} colonnes")
    
    full_filename_base = f"reviews_bulk_{'apercu' if is_preview else 'complet'}"
    display_download_buttons(df_full, full_filename_base, mode="bulk_complet")


def display_bulk_analytics():
    """Affiche des analyses rapides des donn√©es bulk"""
    if not st.session_state.get("all_docs"):
        return
    
    st.markdown("---")
    st.header("üìà Analyses rapides (Bulk)")
    
    docs = st.session_state.all_docs
    df = pd.json_normalize(docs)
    
    if df.empty:
        st.warning("Aucune donn√©e √† analyser")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üè¢ R√©partition par marque")
        if 'brand' in df.columns:
            brand_counts = df['brand'].value_counts().head(10)
            st.bar_chart(brand_counts)
        else:
            st.info("Colonne 'brand' non disponible")
    
    with col2:
        st.markdown("### ‚≠ê R√©partition des notes")
        if 'rating' in df.columns:
            rating_counts = df['rating'].value_counts().sort_index()
            st.bar_chart(rating_counts)
        elif 'note' in df.columns:
            rating_counts = df['note'].value_counts().sort_index()
            st.bar_chart(rating_counts)
        else:
            st.info("Colonne de notation non disponible")
    
    # Tableau r√©capitulatif
    st.markdown("### üìä R√©sum√© statistique")
    
    summary_data = []
    
    # Nombre total
    summary_data.append({"M√©trique": "Total reviews", "Valeur": f"{len(df):,}"})
    
    # Marques uniques
    if 'brand' in df.columns:
        summary_data.append({"M√©trique": "Marques uniques", "Valeur": df['brand'].nunique()})
    
    # Produits uniques
    if 'product' in df.columns:
        summary_data.append({"M√©trique": "Produits uniques", "Valeur": df['product'].nunique()})
    
    # Pays uniques
    if 'country' in df.columns:
        summary_data.append({"M√©trique": "Pays repr√©sent√©s", "Valeur": df['country'].nunique()})
    
    # P√©riode
    if 'date' in df.columns:
        try:
            df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce')
            min_date = df['date_parsed'].min()
            max_date = df['date_parsed'].max()
            if pd.notna(min_date) and pd.notna(max_date):
                summary_data.append({"M√©trique": "P√©riode couverte", "Valeur": f"{min_date.strftime('%Y-%m-%d')} ‚Üí {max_date.strftime('%Y-%m-%d')}"})
        except:
            pass
    
    if summary_data:
        summary_df = pd.DataFrame(summary_data)
        st.dataframe(summary_df, use_container_width=True)


def display_current_bulk_configuration():
    """Affiche la configuration bulk actuelle pour export"""
    if not st.session_state.get("filters"):
        return
    
    st.markdown("---")
    st.header("üíæ Configuration bulk actuelle")
    
    # Configuration sans s√©lection sp√©cifique de produits (mode bulk)
    export_config = export_configuration_to_json(
        st.session_state.filters,
        selected_products=None  # Pas de s√©lection sp√©cifique en mode bulk
    )
    
    # Ajouter une note sur le mode bulk
    export_config["export_mode"] = "BULK_BY_BRAND"
    export_config["note"] = "Configuration pour export bulk - tous les produits des marques s√©lectionn√©es"
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("Configuration JSON pour export bulk :")
        st.code(json.dumps(export_config, indent=2), language="json")
    
    with col2:
        # Bouton de t√©l√©chargement
        config_json = json.dumps(export_config, indent=2)
        st.download_button(
            "üíæ T√©l√©charger config bulk",
            config_json,
            file_name="config_export_bulk.json",
            mime="application/json"
        )
        
        # Informations sur la config
        st.info("""
        **Cette configuration :**
        ‚úÖ Inclut tous les filtres
        ‚úÖ Mode bulk activ√©
        ‚úÖ Pas de s√©lection produit
        ‚úÖ R√©utilisable dans ce module
        """)


def main():
    """Interface principale du module export bulk"""
    initialize_session_state()
    
    st.title("üöÄ Module 3 - Export Bulk")
    st.markdown("Exportez massivement par marque sans s√©lection individuelle de produits")
    
    # Interface de configuration
    display_configuration_interface()
    
    # Si configuration charg√©e
    if st.session_state.get("apply_filters") and st.session_state.get("filters"):
        # R√©sum√© de la configuration bulk
        display_bulk_configuration_summary()
        
        # Interface d'export bulk
        display_bulk_export_interface()
        
        # Affichage des r√©sultats
        display_bulk_export_results()
        
        # Analyses rapides
        display_bulk_analytics()
        
        # Configuration pour r√©utilisation
        display_current_bulk_configuration()
    
    else:
        st.markdown("""
        ## üëã Bienvenue dans l'Export Bulk
        
        Ce module vous permet d'exporter massivement toutes les reviews des marques s√©lectionn√©es.
        
        ### üöÄ Avantages du mode bulk :
        - **Export rapide en masse** : Toutes les reviews des marques en une fois
        - **Pas de s√©lection produit** : Automatiquement tous les produits
        - **Id√©al pour l'analyse** : Datasets complets pour √©tudes approfondies
        - **Moins d'appels API** : Pagination optimis√©e pour gros volumes
        
        ### üìã Pour commencer :
        1. **Chargez une configuration** (Module 1 ou 2)
        2. **V√©rifiez** les marques s√©lectionn√©es
        3. **Estimez le volume** total toutes marques confondues
        4. **Lancez l'export bulk** en mode aper√ßu ou complet
        5. **Analysez** et t√©l√©chargez les r√©sultats
        
        ### üí° Cas d'usage parfaits :
        - Analyse concurrentielle multi-marques
        - √âtudes de march√© sectorielles  
        - Benchmarking produits √† grande √©chelle
        - Constitution de datasets d'entra√Ænement
        
        ### ‚ö†Ô∏è Recommandations :
        - Testez d'abord avec l'aper√ßu (100 reviews)
        - Les exports complets peuvent √™tre tr√®s volumineux
        - Surveillez vos quotas API
        - Utilisez des filtres temporels pour limiter le volume
        """)


if __name__ == "__main__":
    main()
